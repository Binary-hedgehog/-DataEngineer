# Общая информация для подготовки разработчика к собеседованию
## Оглавление
+ [GIT](#git)
+ [Принципы разработки](#принципы-разработки)
+ [Термины](#Термины)
    + [Парадигмы программирования](#Парадигмы-программирования)
    + [Ect](#Ect)
+ [Алгоритмы](#алгоритмы)
+ [Тестирование](#Тестирование)
+ [Алгоритмы кластеризации](#алгоритмы-кластеризации)
+ [Контейнеры](#Контейнеры)
    + [Docker](#Docker)
    + [Kubernetes](#Kubernetes)
+ ci/cd -- todo 
---
## Другие файлы
* [Spark](https://github.com/Binary-hedgehog/-DataEngineer/blob/main/Spark.md)
* [Python](https://github.com/Binary-hedgehog/-DataEngineer/blob/main/Python.md)
* [Scala](https://github.com/Binary-hedgehog/-DataEngineer/blob/main/Scala.md)
* [SQL](https://github.com/Binary-hedgehog/-DataEngineer/blob/main/SQL.md)
* [Вопросы работодателю](https://github.com/Binary-hedgehog/-DataEngineer/blob/main/Questions%20for%20employer.md)
---
## GIT
[Go Back](#оглавление)
* Базовые команды с описаниями и примерами - https://github.com/cyberspacedk/Git-commands
* Gitbook - https://git-scm.com/book/ru/v2/
* GIT flow - альтернативная модель ветвления Git, в которой используются функциональные ветки и несколько основных веток
  * Из ветки main создается ветка develop.
  * Из ветки develop создается ветка release.
  * Из ветки develop создаются ветки feature.
  * Когда работа над веткой feature завершается, она сливается в ветку develop.
  * Когда работа над веткой release завершается, она сливается с ветками develop и main.
  * Если в ветке main обнаруживается проблема, из main создается ветка hotfix.
  * Когда работа над веткой hotfix завершается, она сливается с ветками develop и main.
* Магистральная разработка (Trunk Based Development, TBD) - это модель ветвления системы управления версиями, при которой все разработчики работают в одной ветке. Она помогает добиться CI/CD, ускорить поставку программного обеспечения и повысить производительность организации
  * В TBD в основную ветку добавляются в том числе и не до конца реализованные «фичи»
  * Добавление небольших изменений
  * Флаги активных функций
  * Полное покрытие тестами
---
## Принципы разработки
[Go Back](#оглавление)
* Главное в принципах и подходах - помнить, что все это рекомендации, которые могут быть, а могут и не быть уместными в конкретном проекте и конкретной команде
* Дейлайте хорошо, а не хорошо не делайте!
#### KISS - Keep It Simple Stupid
* Ваши методы должны быть небольшими, не превышающими 40-50 строк
* Каждый метод должен решать только одну проблему
* У вас в проекте много условий? Убедитесь, что вы разбили их на более мелкие блоки кода
#### YAGNI - You Aren't Gonna Need It
* Не оставлять в коде не использующиеся функции, которые "пригодятся когда-то потом"
#### Measure Twice and Cut Once
* Некачественно выполненный этап написания требований обычно приводит к более чем 50% проблем в разработке
* Дважды проверьте все требования проекта, чтобы убедиться, что вы ничего не упускаете и не добавляете лишнего в свой код
#### DRY - Don’t Repeat Yourself
* Избегайте копирования кода в разные места
* Кроме того автоматизируйте всё, что можно автоматизировать
#### Бритва Оккама
* В группе гипотез всегда выбирайте ту, которая имеет наименьшее количество предположений
* *Всегда начинайте с максимально простого кода
#### BDUF - Big Design Up Front
* Разработчик должен сначала завершить проектирование. После этого проект можно реализовать
* Сначала создать общую архитектуру
* Затем необходимо разделить требования на несколько этапов в соответствии с приоритетами
* В процессе разработки начните с этапа с самым высоким приоритетом, постепенно опускаясь до самого низкого
#### Избегайте преждевременной оптимизации
* Дональд Кнут утверждал, что корень всего зла в программировании - преждевременная оптимизация
#### Закон Деметры
* Обеспечить независимость программных объектов друг от друга
* Уменьшить общение или связь между разными классами
* Поместить связанные классы в один и тот же пакет, модуль или каталог для достижения согласованности
#### S.O.L.I.D 
* S - Single Responsibility Principle (SRP) - Принцип единой ответственности
* O - Open/Closed Principle (OCP) - Принцип открытия / закрытия
* L - Liskov Substitution Principle - Принцип замещения Лисков
* I - Interface Segregation Principle - Принцип разделения интерфейса
* D - Dependency Inversion Principle - Принцип инверсии зависимостей
#### CI/CD
* Непрерывная интеграция (CI): короткоживущие функциональные ветки, команда сливает их с основной веткой разработки по несколько раз в день, процессы сборки и тестирования полностью автоматизированы, результат имеем в пределах 10 минут; развертывание выполняется вручную
* Непрерывная доставка (CD): автоматизируется CI + весь процесс релиза ПО. Может состоять из нескольких этапов. Развертывание в продакшен выполняется вручную
* Непрерывное развертывание: CI + CD + полностью автоматизированное развертывание в продакшен
---
## Термины
[Go Back](#оглавление)
### Парадигмы программирования
* Императивное программирование
    * Стиль, в котором код записывается как последовательные инструкции (команды)
    * Каждая инструкция изменяет состояние программы
    * В таком подходе активно используются операции присванивания
    * Почти все ЯП в той или иной степени поддерживают данный стиль
* Декларативное программирование
    * Стиль, в котором описывается желаемый результат, а не способ его получения
    * Декларативные программы не используют понятия состояния, в частности, не содержат переменных и операторов присваивания
    * Примеры ЯП - SQL, HTML
    * «Чисто декларативные» компьютерные языки зачастую неполны по Тьюрингу — так как теоретически не всегда возможно порождение исполняемого кода по декларативному описанию. Это иногда приводит к спорам о корректности термина «декларативное программирование»
* Функциональное программирование
* Объектно-ориентированное программирование
* Структруное программирование
* Процедурное программирование
* Модульное программирование
### Ect
* Сериализация — это процесс преобразования объекта в последовательность байтов, которая может быть сохранена на диске или в базе данных или может быть отправлена в виде потока
    * Обратный процесс - десериализация 
---
## Алгоритмы
[Go Back](#оглавление)
* О-большое описывает скорость работы алгоритма (не время)
* Простой поиск О(n)
* Бинарный поиск O(log n)
#### Рекурсия
* Рекурсия – когда функция вызывает саму себя. Логика рекурсивной функции как правило состоит из двух ветвей. Длинная ветвь вызывает эту же функцию с другими параметрами, чтобы накопить результат. Короткая ветвь определяет критерий выхода из рекурсии
* Неоптимизированная рекурсия приводит к накладным расходам ресурсов
* Хвостовая рекурсия
    * Это особый вид рекурсии, когда функция заканчивается вызовом самой себя без дополнительных операторов
    * Когда это условие выполняется, компилятор разворачивает рекурсию в цикл с одним стек-фреймом, просто меняя локальные переменные от итерации к итерации (интерпретатор Python не умеет оптимизировать это)
#### Быстрая сортировка
* На первом этапе выбирают опорный элемент (чаще всего его берут из середины массива)
* Последовательно сравнивают первый элемент массива с последним, второй с предпоследним и т.д. Если элемент слева от опорного элемента больше правого, они меняются местами
* Когда доходят до опорного элемента, итерация считается законченной
* Сложность быстрой сортировки в среднем случае равна N * log(N)
#### Алгоритм Дейкстры
* Используется для нахождения пути с наименьшим весом в взвешенном графе
* Работает только в направленных ациклических графах (DAG - Directed Acyclic Graph)
* Состоит из 4 шагов:
  * Найти узел с наименьшей стоимостью
  * Обновить стоимость соседей этого узла
  * Повторять пока это не будет сделано для всех узлов
  * Вычислить итоговый путь 
* Не работает с отрицательными весами - для графов с отрицательными весами существует специальный алгоритм, называемый алгоритмом Беллмана-Форда
#### Жадные алгоритмы
* Используются, когда вычисление точного решения занимает слишком много времени или когда высокая точность не требуется
* Эффективность приближенного алгоритма оценивается по:
  * Быстроте
  * Близости полученного решения к оптимальному
---
## Тестирование
[Go Back](#оглавление)
* Unit-тесты
    * Модульные тесты проверяют, правильно ли работает каждый отдельный модуль
    * Модульные тесты не должны проверять внешние зависимости или взаимодействия
    * Вы должны писать и запускать модульные тесты параллельно со своим кодом
* Интеграционные тесты
    * Интеграционные тесты проверяют взаимодействие между двумя (или больше, чем двумя) отдельными юнитами вашего кода
    * Интеграционные тесты также проверяют интеграцию вашего кода с внешними зависимостями, вроде соединений с базой данных или сторонними API
    * Интеграционные тесты — это следующий шаг после модульных тестов
* Функциональное тестирование
    * Функциональное тестирование может быть определено как тестирование отдельных функций модулей
    * Это относится к тестированию программного продукта на индивидуальном уровне, чтобы проверить его функциональность
    * Оно сильно отличается от модульного или интеграционного тестирования; вы не можете написать бесчисленное множество тест-кейсов для функционального тестирования, поскольку оно является более сложным, чем модульное
* Системный тест
    * Автоматизированные тесты, проверяющие работу всей интегрированной системы (предельный случай интеграционных тестов)
    * Системное — это тестирование программы в целом
    * Для небольших проектов это, как правило, ручное тестирование — запустил, пощелкал, убедился, что (не) работает
    * Системные тесты покрывают 10 % системы. Это объясняется тем, что они предназначены для проверки правильности не поведения системы, а ее конструкции
* Регрессионное тестирование
    * Это может быть любой вид теста из описанных выше, который пишется после того, как была обнаружена проблема
    *  Тест должен эмулировать в точности шаги для воспроизведения проблемы. Наличие такого теста после исправления проблемы дает гарантию, что точно такой же баг, больше не появится в системе
---
## Алгоритмы кластеризации 
[Go Back](#оглавление)
* Формально это больше про ML, но не помешает знать, что такое существует
* Кластеризация (или кластерный анализ) — это задача разбиения множества объектов на группы, называемые кластерами. Внутри каждой группы должны оказаться «похожие» объекты, а объекты разных группы должны быть как можно более отличны. Главное отличие кластеризации от классификации состоит в том, что перечень групп четко не задан и определяется в процессе работы алгоритма
* Виды:
  * `Иерархический`
  * `k-средних`
  * `с-средних`
  * `Выделение связных компонент`
  * `Минимально покрывающее дерево`
  * `Послойная кластеризация`
* Ссылка на статью с подробным описанием - https://habr.com/ru/articles/101338/
---
## Контейнеры
### Docker
[Go Back](#оглавление)
* Докер — это открытая платформа для разработки, доставки и эксплуатации приложений
* В своем ядре docker позволяет запускать практически любое приложение, безопасно изолированное в контейнере
* Безопасная изоляция позволяет вам запускать на одном хосте много контейнеров одновременно
* Легковесная природа контейнера, который запускается без дополнительной нагрузки гипервизора, позволяет вам добиваться больше от вашего железа
* Платформа и средства контейнерной виртуализации могут быть полезны в следующих случаях:
    * Упаковывание вашего приложения (и так же используемых компонент) в docker контейнеры;
    * Раздача и доставка этих контейнеров вашим командам для разработки и тестирования;
    * Выкладывания этих контейнеров на ваши продакшены, как в дата центры так и в облака.
* Архитектура Docker
    * Docker использует архитектуру клиент-сервер. Docker клиент общается с демоном Docker, который берет на себя тяжесть создания, запуска, распределения ваших контейнеров. Оба, клиент и сервер могут работать на одной системе, вы можете подключить клиент к удаленному демону docker. Клиент и сервер общаются через сокет или через RESTful API
    * Docker-демон запускается на хост-машине. Пользователь не взаимодействует с сервером на прямую, а использует для этого клиент
    * Docker-клиент, программа docker — главный интерфейс к Docker. Она получает команды от пользователя и взаимодействует с docker-демоном
* Внутри docker-а
    * Образы - это read-only шаблон. Например, образ может содержать операционку Ubuntu c Apache и приложением на ней. Образы используются для создания контейнеров. Docker позволяет легко создавать новые образы, обновлять существующие, или вы можете скачать образы созданные другими людьми. Образы — это компонента сборки docker-а
    * Реестр - Docker-реестр хранит образы. Есть публичные и приватные реестры, из которых можно скачать либо загрузить образы. Публичный Docker-реестр — это Docker Hub. Там хранится огромная коллекция образов. Как вы знаете, образы могут быть созданы вами или вы можете использовать образы созданные другими. Реестры — это компонента распространения
    * Контейнеры - в них содержится все, что нужно для работы приложения. Каждый контейнер создается из образа. Контейнеры могут быть созданы, запущены, остановлены, перенесены или удалены. Каждый контейнер изолирован и является безопасной платформой для приложения. Контейнеры — это компонента работы
* Примеры команд и использования
    * https://losst.pro/zapusk-kontejnera-docker
### Kubernetes
[Go Back](#оглавление)
* Управляет и запускает контейнеры Docker на большом количестве хостов, а так же обеспечивает совместное размещение и репликацию большого количества контейнеров
* В проекте предлагается высокоуровневый API, определяющее логическое группирование контейнеров, позволяющее определять пулы контейнеров, балансировать нагрузку, а также задавать их размещение
* Термины
    * Нода - на каждой ноде Kubernetes запускаются сервисы, необходимые для управления нодой со стороны мастера и для запуска приложений. Конечно, на каждой ноде запускается Docker. Docker обеспечивает загрузку образов и запуск контейнеров
    * Kubelet - управляет pod'ами их контейнерами, образами, разделами, etc
    * Kube-Proxy - proxy-балансировщик. Этот сервис запускается на каждой ноде и настраивается в Kubernetes API. Kube-Proxy может выполнять простейшее перенаправление потоков TCP и UDP (round robin) между набором бэкендов
    * Kubernetes API Server - предназначен для того, чтобы быть CRUD сервером со встроенной бизнес-логикой, реализованной в отдельных компонентах или в плагинах. Он, в основном, обрабатывает REST операции, проверяя их и обновляя соответствующие объекты в etcd (и событийно в других хранилищах)
    * Scheduler - привязывает незапущенные pod'ы к нодам через вызов /binding API. Scheduler подключаем; планируется поддержка множественных scheduler'ов и пользовательских scheduler'ов
    * Kubernetes Controller Manager Server - все остальные функции уровня кластера представлены в Controller Manager. Например, ноды обнаруживаются, управляются и контролируются средствами node controller. Эта сущность в итоге может быть разделена на отдельные компоненты, чтобы сделать их независимо подключаемыми
---
